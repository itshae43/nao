import type { AnthropicProviderOptions } from '@ai-sdk/anthropic';
import type { GoogleGenerativeAIProviderOptions } from '@ai-sdk/google';
import type { MistralLanguageModelOptions } from '@ai-sdk/mistral';
import type { OpenAIResponsesProviderOptions } from '@ai-sdk/openai';
import type { OpenRouterProviderOptions } from '@openrouter/ai-sdk-provider';
import type { OllamaChatProviderOptions } from 'ai-sdk-ollama';
import { z } from 'zod/v4';

import { TokenCost } from './chat';

export const llmProviderSchema = z.enum(['openai', 'anthropic', 'google', 'mistral', 'openrouter', 'ollama']);
export type LlmProvider = z.infer<typeof llmProviderSchema>;

export const llmConfigSchema = z.object({
	id: z.string(),
	provider: llmProviderSchema,
	apiKeyPreview: z.string().nullable(),
	enabledModels: z.array(z.string()).nullable(),
	baseUrl: z.string().url().nullable(),
	createdAt: z.date(),
	updatedAt: z.date(),
});

/** Flatten an interface into a plain type so it gains an implicit index signature. */
type Flatten<T> = { [K in keyof T]: T[K] };

/** Map each provider to its specific config type */
export type ProviderConfigMap = {
	google: GoogleGenerativeAIProviderOptions;
	openai: OpenAIResponsesProviderOptions;
	anthropic: AnthropicProviderOptions;
	mistral: MistralLanguageModelOptions;
	openrouter: OpenRouterProviderOptions;
	ollama: Flatten<OllamaChatProviderOptions>;
};

/** Model definition with provider-specific config type */
type ProviderModel<P extends LlmProvider> = {
	id: string;
	name: string;
	default?: boolean;
	config?: ProviderConfigMap[P];
	costPerM?: TokenCost;
};

/** Provider configuration with typed models */
type ProviderConfig<P extends LlmProvider> = {
	envVar: string;
	baseUrlEnvVar?: string;
	models: readonly ProviderModel<P>[];
	/** Preferred cheap model id for memory extraction. */
	extractorModelId: string;
};

/** Full providers type - each key gets its own config type */
export type LlmProvidersType = {
	[P in LlmProvider]: ProviderConfig<P>;
};

/** A provider + model selection */
export type ModelSelection = {
	provider: LlmProvider;
	modelId: string;
};

export const LLM_INFERENCE_TYPES = ['memory_extraction'] as const;
export type LlmInferenceType = (typeof LLM_INFERENCE_TYPES)[number];
